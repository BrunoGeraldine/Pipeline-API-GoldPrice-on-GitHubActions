import yfinance as yf
import pandas as pd
from datetime import datetime
from pathlib import Path
import sys

from .config import (
    GOLD_TICKER,
    BACKUP_PATH,
    DAILY_PATH,
    CHECKPOINT_PATH,
    get_backup_start_date,
    get_last_business_day
)


def extract_historical_data(start_date: datetime, end_date: datetime = None) -> pd.DataFrame:
    """
    Extract historical gold data via yfinance
    
    Args:
        start_date: Start date
        end_date: End date (default: today)
    
    Returns:
        DataFrame with columns: date, max_price, min_price, closed_price
    """
    if end_date is None:
        end_date = datetime.now()
    
    print(f"ðŸ“Š Extracting data from {GOLD_TICKER}")
    print(f"ðŸ“… Period: {start_date.date()} to {end_date.date()}")
    
    try:
        # Download data from Yahoo Finance
        gold = yf.Ticker(GOLD_TICKER)
        df = gold.history(start=start_date, end=end_date)
        
        if df.empty:
            print("âš ï¸ No data returned from yfinance")
            return pd.DataFrame()
        
        # Standardize columns
        df_clean = pd.DataFrame({
            'date': df.index,
            'max_price': df['High'].values,
            'min_price': df['Low'].values,
            'closed_price': df['Close'].values
        })
        
        # Reset index and convert date to datetime without timezone
        df_clean['date'] = pd.to_datetime(df_clean['date']).dt.tz_localize(None)
        df_clean = df_clean.reset_index(drop=True)
        
        # Ensure correct types
        df_clean['max_price'] = df_clean['max_price'].astype(float)
        df_clean['min_price'] = df_clean['min_price'].astype(float)
        df_clean['closed_price'] = df_clean['closed_price'].astype(float)
        
        print(f"âœ… {len(df_clean)} records extracted")
        return df_clean
        
    except Exception as e:
        print(f"âŒ Error extracting data: {e}")
        return pd.DataFrame()


def create_backup():
    """
    Create complete backup of last 3 years
    """
    print("=" * 60)
    print("ðŸ”„ CREATING HISTORICAL BACKUP (3 YEARS)")
    print("=" * 60)
    
    start_date = get_backup_start_date()
    df = extract_historical_data(start_date)
    
    if df.empty:
        print("âŒ Failed to create backup")
        sys.exit(1)
    
    # Save backup
    df.to_parquet(BACKUP_PATH, index=False)
    print(f"âœ… Backup saved: {BACKUP_PATH}")
    print(f"ðŸ“Š Total records: {len(df)}")
    print(f"ðŸ“… Period: {df['date'].min()} to {df['date'].max()}")
    
    # Update checkpoint
    with open(CHECKPOINT_PATH, 'w') as f:
        f.write(df['date'].max().isoformat())
    
    print(f"âœ… Checkpoint updated: {df['date'].max().date()}")
    return df


def incremental_update():
    """
    Incremental update: adds only new data
    """
    print("=" * 60)
    print("ðŸ”„ INCREMENTAL UPDATE")
    print("=" * 60)
    
    # Check if checkpoint exists
    if not CHECKPOINT_PATH.exists():
        print("âš ï¸ Checkpoint not found. Creating complete backup...")
        return create_backup()
    
    # Read last processed date
    with open(CHECKPOINT_PATH, 'r') as f:
        last_update_str = f.read().strip()
        last_update = pd.to_datetime(last_update_str)
    
    print(f"ðŸ“… Last update: {last_update.date()}")
    
    # Calcular perÃ­odo incremental
    last_business_day = get_last_business_day()
    
    if last_update.date() >= last_business_day.date():
        print("âœ… Dados jÃ¡ estÃ£o atualizados")
        return None
    
    print(f"ðŸ“¥ Buscando dados de {last_update.date()} atÃ© {last_business_day.date()}")
    
    # Extrair novos dados
    df_new = extract_historical_data(
        start_date=last_update + pd.Timedelta(days=1),
        end_date=last_business_day
    )
    
    if df_new.empty:
        print("âš ï¸ Nenhum dado novo disponÃ­vel")
        return None
    
    # Carregar dados existentes
    if DAILY_PATH.exists():
        df_existing = pd.read_parquet(DAILY_PATH)
        print(f"ðŸ“‚ Dados existentes: {len(df_existing)} registros")
    else:
        df_existing = pd.DataFrame()
        print("ðŸ“‚ Creating daily data file")
    
    # Consolidate data
    df_consolidated = pd.concat([df_existing, df_new], ignore_index=True)
    
    # Remove duplicates (if any)
    df_consolidated = df_consolidated.drop_duplicates(subset=['date'], keep='last')
    df_consolidated = df_consolidated.sort_values('date').reset_index(drop=True)
    
    # Salvar dados consolidados
    df_consolidated.to_parquet(DAILY_PATH, index=False)
    print(f"âœ… Dados salvos: {DAILY_PATH}")
    print(f"ðŸ“Š Total consolidado: {len(df_consolidated)} registros")
    print(f"ðŸ“Š Novos registros: {len(df_new)}")
    
    # Atualizar checkpoint
    new_checkpoint = df_new['date'].max()
    with open(CHECKPOINT_PATH, 'w') as f:
        f.write(new_checkpoint.isoformat())
    
    print(f"âœ… Checkpoint atualizado: {new_checkpoint.date()}")
    
    # Mostrar Ãºltimos registros
    print("\nðŸ“‹ Ãšltimos 5 registros:")
    print(df_consolidated.tail().to_string(index=False))
    
    return df_new


def main():
    """
    Main function: decides between backup or incremental
    """
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--backup":
        create_backup()
    else:
        incremental_update()


if __name__ == "__main__":
    main()